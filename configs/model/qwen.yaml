name: qwen-72b
provider: local
model_path: Qwen/Qwen-72B-Chat
model_type: qwen
temperature: 0.7
max_tokens: 2048
top_p: 0.95

# Model-specific settings
tensor_parallel_size: 4  # Adjust based on available GPUs
gpu_memory_utilization: 0.85
max_num_batched_tokens: 4096

# Prompt formatting
system_prompt_prefix: "System: "
user_prompt_prefix: "User: "
assistant_prompt_prefix: "Assistant: "
prompt_separator: "\n"

# Sampling settings
top_k: 50
repetition_penalty: 1.1
presence_penalty: 0.0
frequency_penalty: 0.0 